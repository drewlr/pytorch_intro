{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percepetrons as logical operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (0, 1), (1, 0), (1, 1)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      " Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "       0          0                  -2.0                    0          Yes\n",
      "       0          1                  -1.0                    0          Yes\n",
      "       1          0                  -1.0                    0          Yes\n",
      "       1          1                   0.0                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 1\n",
    "weight2 = 1.0\n",
    "bias = -2.0\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, False, False, True]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = -1\n",
    "b = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= 1 -> y= 0\n",
      "x= 0 -> y= 1\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "print('x=',x,'-> y=',w*x+b )\n",
    "\n",
    "x = 0\n",
    "print('x=',x,'-> y=',w*x+b )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiration: https://github.com/yang-zhang/deep-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic example: y = scalar, x = scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     x =  tensor(2., requires_grad=True)\n",
      "     y =  tensor(12., grad_fn=<MulBackward0>)\n",
      "x.grad =  None\n",
      "\n",
      "After calling y.backward() once: we calculate the grad of y w.r.t. x, and assign this value to x.grad\n",
      "\n",
      "     x =  tensor(2., requires_grad=True)\n",
      "     y =  tensor(12., grad_fn=<MulBackward0>)\n",
      "x.grad =  tensor(12.)\n",
      "   6*x =  tensor(12., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = tensor(2.0, requires_grad=True)\n",
    "y = 3*x**2\n",
    "print('     x = ', x)\n",
    "print('     y = ', y)\n",
    "print('x.grad = ', x.grad)\n",
    "print('\\nAfter calling y.backward() once: we calculate the grad of y w.r.t. x, and assign this value to x.grad\\n')\n",
    "y.backward()\n",
    "print('     x = ', x)\n",
    "print('     y = ', y)\n",
    "print('x.grad = ', x.grad)\n",
    "print('   6*x = ', 6*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accumulating gradients** \n",
    "\n",
    "If now we create another variable as a function of x, and calculate the grad...we will notice that the grad does not match the derivative. Reason for this, is that x.grad accumulates the gradients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad =  tensor(12.)\n",
      "\n",
      "Calling z.backward():\n",
      "     x =  tensor(2., requires_grad=True)\n",
      "     z =  tensor(16., grad_fn=<MulBackward0>)\n",
      "   8*x =  tensor(16., grad_fn=<MulBackward0>)\n",
      "x.grad =  tensor(28.)\n",
      "8*x + previous_grad =  tensor(28., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#x = tensor(2.0, requires_grad=True)\n",
    "print('x.grad = ', x.grad)\n",
    "previous_grad = x.grad.clone()\n",
    "z = 4*x**2\n",
    "\n",
    "print('\\nCalling z.backward():')\n",
    "z.backward()\n",
    "print('     x = ', x)\n",
    "print('     z = ', z)\n",
    "\n",
    "print('   8*x = ', 8*x)\n",
    "print('x.grad = ', x.grad)\n",
    "print('8*x + previous_grad = ', 8*x + previous_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can address this by setting x.grad = None, or by calling zero_grad() while training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad =  None\n"
     ]
    }
   ],
   "source": [
    "x.grad = None\n",
    "print('x.grad = ', x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y = vector, x = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output grad = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "  tensor([[0.2873],\n",
      "        [0.3655]], requires_grad=True)\n",
      "\n",
      "y= x[0]**3 + 2*x[1]**2:\n",
      "  tensor([0.2910], grad_fn=<AddBackward0>)\n",
      "\n",
      "x.grad:\n",
      "  None\n",
      "\n",
      "---\n",
      "After calling y.backward() once: we calculate the grad of y w.r.t. x, and assign this value to x.grad\n",
      "\n",
      "x:\n",
      "  tensor([[0.2873],\n",
      "        [0.3655]], requires_grad=True)\n",
      "y:\n",
      "  tensor([0.2910], grad_fn=<AddBackward0>)\n",
      "\n",
      "x.grad:\n",
      "  tensor([[0.2477],\n",
      "        [1.4622]])\n",
      "\n",
      "3*x[0]**2, 4*x[1]:\n",
      "  tensor([0.2477], grad_fn=<MulBackward0>) \n",
      " tensor([1.4622], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 1).requires_grad_(True)\n",
    "y = x[0]**3 + 2*x[1]**2\n",
    "\n",
    "print('x:\\n ', x)\n",
    "print('\\ny= x[0]**3 + 2*x[1]**2:\\n ', y)\n",
    "print('\\nx.grad:\\n ', x.grad)\n",
    "\n",
    "print('\\n---\\nAfter calling y.backward() once: we calculate the grad of y w.r.t. x, and assign this value to x.grad\\n')\n",
    "y.backward(gradient=torch.ones(1))\n",
    "print('x:\\n ', x)\n",
    "print('y:\\n ', y)\n",
    "print('\\nx.grad:\\n ', x.grad)\n",
    "print('\\n3*x[0]**2, 4*x[1]:\\n ', 3*x[0]**2,'\\n', 4*x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x = scalar, y = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "  tensor([0.4187], requires_grad=True)\n",
      "\n",
      " y[0] = x**3\n",
      "\n",
      " y[1] = 2*x**2\n",
      "\n",
      "x.grad:\n",
      "  None\n",
      "\n",
      "---\n",
      "After calling y.backward() once: we calculate the grad of y w.r.t. x, and assign this value to x.grad\n",
      "\n",
      "x:\n",
      "  tensor([0.4187], requires_grad=True)\n",
      "y:\n",
      "  tensor([[0.0734],\n",
      "        [0.3505]], grad_fn=<CopySlices>)\n",
      "\n",
      "x.grad:\n",
      "  tensor([2.2004])\n",
      "\n",
      "3*x**2 + 4*x:\n",
      "  tensor([2.2004], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.rand(1), requires_grad=True)\n",
    "y = Variable(torch.zeros(2, 1), requires_grad=False)\n",
    "y[0] = x**3\n",
    "y[1] = 2*x**2\n",
    "\n",
    "print('x:\\n ', x)\n",
    "print('\\n y[0] = x**3')\n",
    "print('\\n y[1] = 2*x**2')\n",
    "print('\\nx.grad:\\n ', x.grad)\n",
    "\n",
    "print('\\n---\\nAfter calling y.backward() once: we calculate the grad of y w.r.t. x, and assign this value to x.grad\\n')\n",
    "y.backward(gradient=torch.ones(y.size()))\n",
    "print('x:\\n ', x)\n",
    "print('y:\\n ', y)\n",
    "print('\\nx.grad:\\n ', x.grad)\n",
    "print('\\n3*x**2 + 4*x:\\n ', 3*x**2 + 4*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.608px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
